{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a48a0d-7465-4b8d-9c86-91863841ec4c",
   "metadata": {},
   "source": [
    "# Train a model to classify DisasterDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd8a44f-511f-4a2e-b867-a682f5fd5eda",
   "metadata": {},
   "source": [
    "dataset source: [nlp-getting-started](https://www.kaggle.com/competitions/nlp-getting-started)\n",
    "\n",
    "First import some related packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c133041f-d9aa-4198-8b80-404a076f9d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from meter import AverageMeter, CumsumMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7fc3f-2df7-4d37-ab0d-4dec84e5703d",
   "metadata": {},
   "source": [
    "Before we step into develop LSTM model, let's clarify the steps of coding with `pytorch`\n",
    "\n",
    "STEP:\n",
    "1. Load data, create CV(cross validation) and tokenize into word ids.\n",
    "2. Create `Dataset` class to load the data, and then make dataloader\n",
    "3. Create Model class with `nn.Module`\n",
    "4. Load pretrained embeddings\n",
    "5. Create model training function\n",
    "6. Create model instance, optimizer, scheduler, loss_function, ...\n",
    "7. Train the model with data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895801fe-ff50-4db8-bafe-7bd94eb95a40",
   "metadata": {},
   "source": [
    "After clarify how we train a model, let's create some helper class and function\n",
    "\n",
    "`Tokenizer`: tokenizer for text.\n",
    "\n",
    "`DisasterDataset`: `pytorch dataset` that be used to load data\n",
    "\n",
    "`load_embeddings`: load pretrained embeddings\n",
    "\n",
    "`LSTMModel`: `pytorch model`, define how model do forward-propgation\n",
    "\n",
    "`train_one_epoch`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba3bcce-cb87-477c-bf68-a411e6caf9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.vocab = []\n",
    "        self.word2id = {}\n",
    "        self.id2word = {}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.word2id)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _text2word(text):\n",
    "        # to simply the preprocessing and package requirements, use `split` here.\n",
    "        # you can re-write this function to do more accurate tokenize.\n",
    "        return text.split()\n",
    "    \n",
    "    def fit(self, texts):\n",
    "        vocab = set()\n",
    "        for text in texts:\n",
    "            words = self._text2word(text)\n",
    "            vocab |= set(words)\n",
    "        vocab = list(sorted(vocab))\n",
    "        self.vocab = vocab\n",
    "        self.word2id = dict(zip(vocab, range(1, len(vocab) + 1)))\n",
    "        self.id2word = dict(zip(range(1, len(vocab) + 1), vocab))\n",
    "        # save pad token\n",
    "        self.word2id[\"<pad>\"] = 0\n",
    "        self.id2word[0] = \"<pad>\"\n",
    "    \n",
    "    def tokenize(self, text, max_length=54, padding=False, padding_idx=0):\n",
    "        words = self._text2word(text)\n",
    "        word_ids = [self.word2id[word] for word in words if word in self.word2id]\n",
    "        word_ids = word_ids[:max_length]\n",
    "        if padding:\n",
    "            pad_len = max_length - len(word_ids)\n",
    "            word_ids = word_ids + [padding_idx] * pad_len\n",
    "        return word_ids\n",
    "    \n",
    "    def decode(self, word_ids):\n",
    "        words = [self.id2word[word_id] for word_id in word_ids if word_id in self.id2word]\n",
    "        return \" \".join(words)\n",
    "\n",
    "\n",
    "class DisasterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=54):\n",
    "        self.texts = df.text.values.tolist()\n",
    "        if \"target\" in df.columns:\n",
    "            self.target = df.target.values.tolist()\n",
    "        else:\n",
    "            self.target = None\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        text = self.texts[item]\n",
    "        word_ids = self.tokenizer.tokenize(text, max_length=self.max_length, padding=True)\n",
    "        x = torch.LongTensor(word_ids)\n",
    "        if self.target is None:\n",
    "            return x\n",
    "        return x, torch.FloatTensor([self.target[item]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf24ebe-4e65-4025-a533-0ee67e43b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(embedding_file, word2id):\n",
    "    # embeddings = np.random.randn(len(word2id), 300)\n",
    "    dim = int(embedding_file.split(\"/\")[-1].split(\".\")[-2][:-1])\n",
    "    embeddings = np.zeros((len(word2id), dim))\n",
    "    with open(embedding_file, \"r\") as f:\n",
    "        while 1:\n",
    "            line = f.readline().strip()\n",
    "            if not line:\n",
    "                break\n",
    "            word, vec = line.split(\" \", 1)\n",
    "            if word not in word2id:\n",
    "                continue\n",
    "            embeddings[word2id[word]] = np.array([float(i) for i in vec.split(\" \")])\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c91b649c-c41c-4075-8d08-644e6eb49749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, n_vocab, embedding_dim, lstm_dim=256, pretrain_embeddings=None):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        embedding_dim = embedding_dim if pretrain_embeddings is None else pretrain_embeddings.shape[1]\n",
    "        self.embedding = nn.Embedding(num_embeddings=n_vocab, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        if pretrain_embeddings is not None:\n",
    "            self.embedding.weight.data = torch.FloatTensor(pretrain_embeddings)\n",
    "            self.embedding.requires_grad_(False)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_dim // 2, bidirectional=True, batch_first=True)\n",
    "        self.gru = nn.GRU(lstm_dim, lstm_dim, bidirectional=True, batch_first=True)\n",
    "        self.pooler = lambda x: torch.mean(x, dim=1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classification_head = nn.Linear(lstm_dim * 2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x)\n",
    "        h, _ = self.lstm(embed)\n",
    "        h, _ = self.gru(h)\n",
    "        feature = self.pooler(h)\n",
    "        feature = self.dropout(feature)\n",
    "        logits = self.classification_head(feature)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9aba061-7f6d-4439-81bb-23ec8f0fb26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, scheduler, criterion, epoch):\n",
    "    model.train()\n",
    "    progress_bar = tqdm(train_loader, total=len(train_loader))\n",
    "    optimizer.zero_grad()\n",
    "    batch_losses = AverageMeter()\n",
    "    batch_score = CumsumMeter(metrics.f1_score)\n",
    "    progress_bar.set_description(f\"epoch {epoch}\")\n",
    "    for x, y in progress_bar:\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        batch_losses.update(loss.item(), n=y.shape[0])\n",
    "        batch_score.update(y.detach().cpu().numpy(), (logits.detach().sigmoid().cpu().numpy() > 0.42966).astype(int))\n",
    "        progress_bar.set_postfix({\"loss\": batch_losses.avg, \"f1\": batch_score.score})\n",
    "        optimizer.zero_grad()\n",
    "    return batch_losses.avg, batch_score.score\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    batch_losses = AverageMeter()\n",
    "    batch_score = CumsumMeter(metrics.f1_score)\n",
    "    progress_bar = tqdm(val_loader, total=len(val_loader))\n",
    "    for x, y in progress_bar:\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        batch_losses.update(loss.item(), n=y.shape[0])\n",
    "        batch_score.update(y.detach().cpu().numpy(), (logits.detach().sigmoid().cpu().numpy() > 0.42966).astype(int))\n",
    "        progress_bar.set_postfix({\"loss\": batch_losses.avg, \"f1\": batch_score.score})\n",
    "    return batch_losses.avg, batch_score.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6751952-a177-4558-ae92-75d012f01e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.57034\n",
      "1    0.42966\n",
      "Name: target, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./train.csv\")\n",
    "print(df.target.value_counts(normalize=True))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc08551-95e1-41ec-95eb-f22fd6b4a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit(df.text.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "455e516e-0060-4cd6-bbc9-89d1fd7327d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.570279\n",
      "1    0.429721\n",
      "Name: target, dtype: float64\n",
      "0    0.570584\n",
      "1    0.429416\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df, test_size=0.2, random_state=42, stratify=df.target)\n",
    "print(df_train.target.value_counts(normalize=True))\n",
    "print(df_val.target.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8374209c-b3c2-4300-ac73-c1d88c16f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DisasterDataset(df_train, tokenizer=tokenizer)\n",
    "val_set = DisasterDataset(df_val, tokenizer=tokenizer)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=32 * 2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5a8633e-d72c-4259-aff0-50fea30512ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "learning_rate = 3e-4\n",
    "total_steps = len(train_loader) * epochs\n",
    "embeddings = load_embeddings(\"/Users/heyao/learn_from_datasets/embedding/glove.6B.300d.txt\", tokenizer.word2id)\n",
    "model = LSTMModel(len(tokenizer), embedding_dim=128, lstm_dim=128, pretrain_embeddings=embeddings)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13251204-6101-4507-b816-7af524c30ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0: 100%|█████████████████████████████████████████████████████████████████████████| 191/191 [00:08<00:00, 21.58it/s, loss=0.611, f1=0.605]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 31.04it/s, loss=0.533, f1=0.669]\n",
      "epoch 1: 100%|█████████████████████████████████████████████████████████████████████████| 191/191 [00:09<00:00, 21.11it/s, loss=0.528, f1=0.671]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 29.67it/s, loss=0.517, f1=0.689]\n",
      "epoch 2: 100%|██████████████████████████████████████████████████████████████████████████| 191/191 [00:08<00:00, 21.29it/s, loss=0.505, f1=0.69]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 30.40it/s, loss=0.517, f1=0.701]\n",
      "epoch 3: 100%|█████████████████████████████████████████████████████████████████████████| 191/191 [00:09<00:00, 20.78it/s, loss=0.494, f1=0.705]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 30.49it/s, loss=0.505, f1=0.686]\n",
      "epoch 4: 100%|█████████████████████████████████████████████████████████████████████████| 191/191 [00:09<00:00, 20.90it/s, loss=0.479, f1=0.721]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 29.66it/s, loss=0.505, f1=0.697]\n",
      "epoch 5: 100%|█████████████████████████████████████████████████████████████████████████| 191/191 [00:09<00:00, 20.84it/s, loss=0.466, f1=0.732]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 30.22it/s, loss=0.505, f1=0.707]\n",
      "epoch 6: 100%|█████████████████████████████████████████████████████████████████████████| 191/191 [00:09<00:00, 21.19it/s, loss=0.458, f1=0.737]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 29.96it/s, loss=0.513, f1=0.702]\n",
      "epoch 7: 100%|██████████████████████████████████████████████████████████████████████████| 191/191 [00:09<00:00, 20.52it/s, loss=0.45, f1=0.749]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 28.98it/s, loss=0.508, f1=0.705]\n",
      "epoch 8: 100%|█████████████████████████████████████████████████████████████████████████| 191/191 [00:09<00:00, 20.84it/s, loss=0.443, f1=0.753]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 29.08it/s, loss=0.504, f1=0.698]\n",
      "epoch 9: 100%|█████████████████████████████████████████████████████████████████████████| 191/191 [00:09<00:00, 20.72it/s, loss=0.437, f1=0.761]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 29.34it/s, loss=0.511, f1=0.71]\n"
     ]
    }
   ],
   "source": [
    "# 0.697\n",
    "# 0.706\n",
    "for epoch in range(epochs):\n",
    "    train_one_epoch(model, train_loader, optimizer, scheduler, criterion, epoch)\n",
    "    _ = evaluate(model, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a5be644-bd69-4033-b631-24d01a593ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7547, 200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[embeddings.sum(axis=1) != 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf167273-2332-4249-be1d-300fc638eaee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
